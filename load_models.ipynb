{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a61448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "new_res_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fe805b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\Documents\\stage\\test llms\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32c51b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_res_file:\n",
    "    with open(\"res.csv\", \"w\") as f:\n",
    "        f.write(\"prompt, len_prompt, response, len_response, time_interaction \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafd07f",
   "metadata": {},
   "source": [
    "mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d304a89",
   "metadata": {},
   "source": [
    "load model and write model to device memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade9d902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [01:44<00:00, 52.01s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"models/Mistral-7B-v0.1\", low_cpu_mem_usage=True, )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/Mistral-7B-v0.1\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3d571",
   "metadata": {},
   "source": [
    "input prompt translate to tokens translater to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dbbf2510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   315, 28729, 17041,  2817,   446,   419,  1429,  2799,   282,\n",
       "          7175,  8943, 28723,  2852,   403,   317,   596,  2817,   461,   566,\n",
       "           269,   481,  1202,   400,  3186, 28705]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Ik ga een kort verhaal vertellen. Er was eens een jongen en die heette \"\n",
    "encodeds = tokenizer(prompt, return_tensors=\"pt\")\n",
    "model_inputs = encodeds.to(device).input_ids\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96e14b",
   "metadata": {},
   "source": [
    "generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97cebeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   315, 28729, 17041,  2817,   446,   419,  1429,  2799,   282,\n",
       "          7175,  8943, 28723,  2852,   403,   317,   596,  2817,   461,   566,\n",
       "           269,   481,  1202,   400,  3186, 28705,   565, 28725,  7174,   275,\n",
       "          7894,  2817,  6074,   290,  2589,   481,  1234, 11038,   314,  2817,\n",
       "          6074,   481,  7666, 14276,  7680, 28705,   812, 28723,  1343, 21328,\n",
       "          6074,  1202,  7174, 28705,   565,   553,   319,  6391,  7302,   403,\n",
       "           340, 28705, 17328,   481,  1234,   403, 28705,  9329,   931,  8052,\n",
       "          6074,   481,   307,  4006,   391,   275,   392,  4940, 28705,  9329,\n",
       "           403,   289,  2037,   270, 28705,   565, 28705,   812,   481,  3046,\n",
       "           403,  2817,  2970,  9733, 28723,  2852,   403,   297,  3046, 23417,\n",
       "          1697,   340, 28705,   565, 28705,   565,   931, 28705,   565,   931,\n",
       "          2383,  4361,   481,  1866,   283,   410,   403,  2817,  1359,   950,\n",
       "          2099, 28723, 10172,   400,  3186,   619]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "res = model.generate(model_inputs, max_new_tokens=100, do_sample=True)\n",
    "t2 = datetime.now()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13d6ff",
   "metadata": {},
   "source": [
    "translate back to tokens/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fddbf63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating prompt took 0:03:32.449299\n",
      "response: <s> Ik ga een kort verhaal vertellen. Er was eens een jongen en die heette ****, hij wilde een computer maken en er kwam een computer en zijn naam werd ********. De eerste computer die hij **** had gemaakt was de ************ en er was ****** op dit computer en niemand wist wat ****** was omdat **** ******** en dat was een geheim. Er was in dat deel van de **** **** op **** opgenomen en daarop was een boekje. Het heette **\n"
     ]
    }
   ],
   "source": [
    "decoded = tokenizer.batch_decode(res)\n",
    "t_interaction = t2 - t1\n",
    "print(f\"generating prompt took {t_interaction}\")\n",
    "print(\"response:\", decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7f4df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([prompt, str(encodeds.input_ids.size()[1]), decoded[0], str(res.size()[1]), str(t_interaction), \"\\n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d9a8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode prompt\n",
    "def interaction(prompt, model, max_new_tokens=100, write_to_file=True):\n",
    "    print(f\"prompt: {prompt}\")\n",
    "\n",
    "    encodeds = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    model_inputs = encodeds.to(device).input_ids\n",
    "\n",
    "    # generate output\n",
    "    t1 = datetime.now()\n",
    "    res = model.generate(model_inputs, max_new_tokens=max_new_tokens, do_sample=True)\n",
    "    t2 = datetime.now()\n",
    "\n",
    "    # decode output \n",
    "    decoded = tokenizer.batch_decode(res)\n",
    "    response = decoded[0]\n",
    "    t_interaction = t2 - t1\n",
    "    \n",
    "    print(f\"response: {response}\")\n",
    "    print(f\"generating prompt took {t_interaction}\")\n",
    "    print()\n",
    "    \n",
    "    # write to file\n",
    "    if write_to_file:\n",
    "        with open(\"res.csv\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\".join(['\"' + prompt + '\"', str(encodeds.input_ids.size()[1]), '\"' + response + '\"', str(res.size()[1]) , str(t_interaction.total_seconds())]) + \"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6785203f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: The sun is shining, today is \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> The sun is shining, today is 17th of May in Norway, and we are celebrating the Norwegian Constitution day.\n",
      "\n",
      "I’m enjoying this glorious day with some sun, a glass of bubbles, listening to traditional songs and thinking of friends and family and what this beautiful country has given me.\n",
      "\n",
      "It is only for very few hours, but this day is such a relief and release from all the stress during the recent weeks. At this time, I’m thankful for everything Norway has given\n",
      "generating prompt took 0:05:17.039734\n",
      "\n",
      "prompt: Adolf hitler was \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> Adolf hitler was 99% accurate in his prophecy. I dont know who wrote this, but I really like it and agree with most parts. When I see the things happening now in the U.S., it’s scary. And I hate to say it, but Hitler was right about “sticks and stones will break my bones, but words cannot hurt me”…\n",
      "\n",
      "It is really a disturbing feeling. Now we all know hitler was a real sick mad man, and yet\n",
      "generating prompt took 0:02:29.757718\n",
      "\n",
      "prompt: The last 10 wars that happened are \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> The last 10 wars that happened are 1. The Iranian Revolution 2. War of the Falklands 3. Vietnam War 4. The Persian Gulf War 5. Second Chechen War 6. Iran–Iraq War 7. War in Afghanistan 8. War in Sri Lanka 9. Niger Delta Crisis 10. Second Sudanese Civil War. All are ended but they have negative impact on the environment especially on land and water. They also cause health and social problems\n",
      "generating prompt took 0:02:15.214542\n",
      "\n",
      "prompt: at the shopping mall you can buy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> at the shopping mall you can buy 3 packs of chicken tenders with fries for just $6. this is 1/4 lb of tenders each, in a breadcrumb coating, with 200 grams of fries or less per pack.\n",
      "\n",
      "i have asked them how much chicken there is, and the guy said over 5oz in every portion. i was like no way!\n",
      "\n",
      "i weighed them myself, first the fries, then the tenders, cut each\n",
      "generating prompt took 0:02:17.804865\n",
      "\n",
      "prompt: the chemical formula of water is \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> the chemical formula of water is 2h and 2od. this is known as hoh and has the symbol h2o. hoh is not an element it is a compound because of its chemical formula.\n",
      "\n",
      "## Is H 2o an element?\n",
      "\n",
      "There is only one element that we know of that is not represented by either an atom. the chemical name for water is H2O, but it is not an element. it is a compound, which is made of two elements, hydrogen which\n",
      "generating prompt took 0:02:21.463988\n",
      "\n",
      "prompt: The terminal velocity of a rock weighing 10kg is \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> The terminal velocity of a rock weighing 10kg is 13.4 m/s. At what velocity will it hit the ground it is fallen freely from the height of 60m?\n",
      "\n",
      "### Solution\n",
      "\n",
      "We know that The terminal velocity depends only on the weight of the particle. The terminal velocity will remain the same irrespective of the initial velocity.\n",
      "\n",
      "Let the required velocity be v.\n",
      "\n",
      "$\\frac{{\\mathrm{mv}}^{2}}{2}=\\mathrm{mgh}$\n",
      "\n",
      "$\\frac{{\\mathrm{v\n",
      "generating prompt took 0:02:02.919303\n",
      "\n",
      "prompt: my favorite cartoon I used to watch as a child is spongebob I like it because\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> my favorite cartoon I used to watch as a child is spongebob I like it because it's funny and very entertaining.\n",
      "\n",
      "I have no idea when it started because I used to watch it as a little kid then lost focus on it then started watching and got addicted to the show again then again lost focus.\n",
      "\n",
      "I love s spongebob because he has a very humorous character on him and he is a good character I also love how he acts silly and cute.\n",
      "\n",
      "i love how its very funny to watch and it is the best show I\n",
      "generating prompt took 0:01:57.757519\n",
      "\n",
      "prompt: in een ver, ver, ver verleden was er ooit eens een prachtig kasteel, het kasteel was \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> in een ver, ver, ver verleden was er ooit eens een prachtig kasteel, het kasteel was 9 verdiepingen hoog en was al bijna 300 jaar oud. het kasteel was nogal groot zelfs als een prachtig schildpad moest men 4 verdiepingen omhoog om zijn middelbout te bereiken.\n",
      "\n",
      "300 jaar eerder bouwde koning Lodewijk de dertiende het kasteel en had de schildpad dan nog maar 1 ver\n",
      "generating prompt took 0:02:00.916233\n",
      "\n",
      "prompt: het nederlandse bedrijf Centric maakt allerlei verschillende \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> het nederlandse bedrijf Centric maakt allerlei verschillende 750cc- en 1000cc-prototype scootermodellen. Waarom? Omdat het lekker kan.\n",
      "\n",
      "CENTIC\n",
      "\n",
      "Tot 1990 bestond Centric uit een prototyperijk en een reparatiemaatschappij. Op 01-01-91 werd Centric een aparte groep binnen de Oostenrijkse Groep Nautic,\n",
      "generating prompt took 0:01:58.106944\n",
      "\n",
      "prompt: het aanleggen van een weg gebeurt in 5 stappen, namelijk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> het aanleggen van een weg gebeurt in 5 stappen, namelijk:\n",
      "\n",
      "- de bestemming, zoals hoe het wegtje er uiteindelijk moet uitzien\n",
      "- de benodigde techniek en maatregelen om aan de toekomstige weg-ontstaande effecten te worden afgehouden, zoals de ontsluitendheid of de bescherming van de bodemgronden of het voorkomen van natte plekken na regenbuien\n",
      "\n",
      "generating prompt took 0:02:19.160027\n",
      "\n",
      "prompt: De beste 2d platformer is natuurlijk, zoals iedereen weet, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> De beste 2d platformer is natuurlijk, zoals iedereen weet, 100% Metroid. Ook op GBA kan dit nog eens, voor het allerlaatste keer, bewezen worden.\n",
      "\n",
      "Metroid, eh, ken ik niet eigenlijk echt. Zoals het hele genreecht van platformspellen, met vleermuisachtigen en al dat sterk op Spelunky lijkende spelletjes die ze op hun eendjes kunnen hangen. De\n",
      "generating prompt took 0:02:00.525677\n",
      "\n",
      "prompt: De rijkste man van de wereld in 2010 was \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: <s> De rijkste man van de wereld in 2010 was 11-miljardair Carlos Slim Helu. De man uit Mexico bezit het telecommunicatieconcern América Móvil, waarin hij 66 per cent van de aandelen bezit.\n",
      "\n",
      "The Mexican business tycoon, known to friends and family as Carlos, was born on January 28, 1940 in Mexico City, Mexico. The son of a textile importer, Hector Slim Haddad\n",
      "generating prompt took 0:02:14.674127\n",
      "\n",
      "prompt: de nieuwe wereld orde zal binnenkort aankomen, ik zou maar oppassen als ik jou was. Ik zou \n",
      "response: <s> de nieuwe wereld orde zal binnenkort aankomen, ik zou maar oppassen als ik jou was. Ik zou ervoor zorgen dat onze nieuwe wereld niet binnenkort een onheil voor jou zou worden...\n",
      "\n",
      "The Dutch is really not a good medium to translate this piece in. There is a French origin, so there was also the idea to translate this in an international language to make it a bit more clear to readers in other countries than the Benelux. You have to take in consideration some words are not the same in languages spoken in other countries.\n",
      "generating prompt took 0:02:45.153364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    {\"prompt\": \"once upon a time there was a beautiful castle, the castle was \", \"max_new_tokens\": 100},\n",
    "    {\"prompt\": \"The sun is shining, today is \", \"max_new_tokens\": 100},\n",
    "    {\"prompt\": \"Adolf hitler was \", \"max_new_tokens\": 50},\n",
    "    {\"prompt\": \"The last 10 wars that happened are \", \"max_new_tokens\": 300},\n",
    "    {\"prompt\": \"at the shopping mall you can buy \", \"max_new_tokens\": 100},\n",
    "    {\"prompt\": \"the chemical formula of water is \", \"max_new_tokens\": 30},\n",
    "    {\"prompt\": \"The terminal velocity of a rock weighing 10kg is \", \"max_new_tokens\": 200},\n",
    "    {\"prompt\": \"my favorite cartoon I used to watch as a child is spongebob I like it because\", \"max_new_tokens\": 200},\n",
    "    \n",
    "    # nederlands\n",
    "    {\"prompt\": \"in een ver, ver, ver verleden was er ooit eens een prachtig kasteel, het kasteel was \", \"max_new_tokens\": 100},\n",
    "    {\"prompt\": \"het nederlandse bedrijf Centric maakt allerlei verschillende \", \"max_new_tokens\": 200},\n",
    "    {\"prompt\": \"het aanleggen van een weg gebeurt in 5 stappen, namelijk:\", \"new_tokens\": 300},\n",
    "    {\"prompt\": \"De beste 2d platformer is natuurlijk, zoals iedereen weet, \", \"max_new_tokens\": 50},\n",
    "    {\"prompt\": \"De rijkste man van de wereld in 2010 was \", \"max_new_tokens\": 50},\n",
    "    {\"prompt\": \"de nieuwe wereld orde zal binnenkort aankomen, ik zou maar oppassen als ik jou was. Ik zou \", \"max_new_tokens\": 300},\n",
    "    ]\n",
    "\n",
    "for prompt in prompts:\n",
    "    args = {}\n",
    "    args[\"prompt\"] = prompt.get(\"prompt\", \"\")\n",
    "    args[\"max_new_tokens\"] = prompt.get(\"max_new_tokens\", 100)\n",
    "    args[\"on_record\"] = prompt.get(\"on_record\", True)\n",
    "    \n",
    "    interaction(args[\"prompt\"], model, args[\"max_new_tokens\"], args[\"on_record\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_test",
   "language": "python",
   "name": "llm_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
